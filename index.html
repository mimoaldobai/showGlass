<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Virtual Glasses Try-On</title>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128/examples/js/loaders/GLTFLoader.js"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            text-align: center;
        }
        video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            z-index: -1;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
    </style>
</head>
<body>
    <video id="video" autoplay muted playsinline></video>
    <script>
        let scene, camera, renderer, glasses;
        let video = document.getElementById("video");

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
            video.srcObject = stream;
            return new Promise((resolve) => {
                video.onloadedmetadata = () => resolve(video);
            });
        }

        async function loadFaceModel() {
            await faceapi.nets.tinyFaceDetector.loadFromUri("https://justadudewhohacks.github.io/face-api.js/models");
            await faceapi.nets.faceLandmark68Net.loadFromUri("https://justadudewhohacks.github.io/face-api.js/models");
        }

        function setupThreeJS() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({ alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);
            
            const light = new THREE.AmbientLight(0xffffff, 1);
            scene.add(light);

            camera.position.z = 1.5;

            const loader = new THREE.GLTFLoader();
            loader.load("glass8k.glb", (gltf) => {
                glasses = gltf.scene;
                glasses.scale.set(0.02, 0.02, 0.02);
                scene.add(glasses);
            });
        }

        async function detectFace() {
            const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
            if (detection) {
                const landmarks = detection.landmarks.positions;
                const leftEye = landmarks[36]; // الزاوية الخارجية للعين اليسرى
                const rightEye = landmarks[45]; // الزاوية الخارجية للعين اليمنى
                const nose = landmarks[30]; // منتصف الأنف

                // حساب موقع النظارات بناءً على العينين
                const glassesX = (leftEye.x + rightEye.x) / 2 - video.videoWidth / 2;
                const glassesY = (leftEye.y + rightEye.y) / 2 - video.videoHeight / 2;
                const distance = Math.hypot(rightEye.x - leftEye.x, rightEye.y - leftEye.y);

                if (glasses) {
                    glasses.position.set(glassesX / 300, -glassesY / 300, -1);
                    glasses.scale.set(distance / 50, distance / 50, distance / 50);
                }
            }
            requestAnimationFrame(detectFace);
        }

        async function main() {
            await setupCamera();
            await loadFaceModel();
            setupThreeJS();
            detectFace();
        }

        main();
    </script>
</body>
</html>
