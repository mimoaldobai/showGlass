<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Virtual Glasses Try-On</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/three/examples/js/loaders/GLTFLoader.js"></script>
</head>
<body style="margin: 0; overflow: hidden;">

    <video id="video" width="640" height="480" autoplay playsinline style="position: fixed; top: 10px; left: 10px; border: 2px solid red;"></video>
    <canvas id="canvas"></canvas>
    <div id="status" style="position: fixed; top: 10px; right: 10px; background: black; color: white; padding: 10px; font-size: 18px;">
        Status: Waiting for face
    </div>

    <script>
        let scene, camera, renderer, model, video, mesh, faceMesh;
        let startTime = null;

        function initThreeJS() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.1, 1000);
            renderer = new THREE.WebGLRenderer({ canvas: document.getElementById("canvas"), alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            // إضافة إضاءة
            const light = new THREE.AmbientLight(0xffffff, 1);
            scene.add(light);

            camera.position.set(0, 0, 1);

            // تحميل النموذج ثلاثي الأبعاد (GLB)
            const loader = new THREE.GLTFLoader();
            loader.load('glass1.glb', function (gltf) {
                model = gltf.scene;
                model.scale.set(0.1, 0.1, 0.1);
                scene.add(model);
                console.log("Model Loaded Successfully");
            }, undefined, function (error) {
                console.error("Error Loading Model:", error);
            });
        }

        async function initFaceMesh() {
            video = document.getElementById("video");
            navigator.mediaDevices.getUserMedia({ video: true })
                .then((stream) => {
                    video.srcObject = stream;
                })
                .catch((err) => console.error("Camera Error:", err));

            faceMesh = new FaceMesh({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
            });
            faceMesh.setOptions({
                maxNumFaces: 1,
                refineLandmarks: true,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });

            faceMesh.onResults(onFaceResults);

            const camera = new Camera(video, {
                onFrame: async () => {
                    await faceMesh.send({ image: video });
                },
                width: 640,
                height: 480
            });
            camera.start();
        }

        function onFaceResults(results) {
            if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {
                document.getElementById("status").innerText = "Status: Waiting for face";
                startTime = null;
                return;
            }

            if (!startTime) {
                startTime = performance.now();
            }

            const elapsedTime = ((performance.now() - startTime) / 1000).toFixed(2);

            document.getElementById("status").innerText = `Status: Face Detected! Time: ${elapsedTime}s`;

            const faceLandmarks = results.multiFaceLandmarks[0];

            // نقاط النظارات
            const leftEye = faceLandmarks[33];
            const rightEye = faceLandmarks[263];
            const nose = faceLandmarks[1];

            // حساب موقع النظارات
            const x = (leftEye.x + rightEye.x) / 2 - 0.5;
            const y = -((leftEye.y + rightEye.y) / 2 - 0.5);
            const z = -((leftEye.z + rightEye.z) / 2);

            if (model) {
                model.position.set(x, y, z - 1);
            }
        }

        function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
        }

        window.onload = function () {
            initThreeJS();
            initFaceMesh();
            animate();
        };
    </script>

</body>
</html>
