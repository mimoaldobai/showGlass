<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>تجربة النظارات الافتراضية</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/three/examples/js/loaders/GLTFLoader.js"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: #000;
            color: white;
            font-family: Arial, sans-serif;
        }
        video {
            position: absolute;
            transform: scaleX(-1); /* عكس الفيديو لمزامنة الوجه */
            opacity: 0.5;
        }
        #status {
            position: absolute;
            top: 10px;
            left: 10px;
            background: rgba(0, 0, 0, 0.7);
            padding: 10px;
            border-radius: 5px;
            font-size: 16px;
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <div id="status">Status: Waiting for face</div>
    <script>
        let scene, camera, renderer, model;
        let startTime = null;

        // إعداد Three.js
        function initScene() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.set(0, 0, 2);

            renderer = new THREE.WebGLRenderer({ alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            // تحميل نموذج النظارات
            const loader = new THREE.GLTFLoader();
            loader.load('glass1.glb', function (gltf) {
                model = gltf.scene;
                model.scale.set(1.5, 1.5, 1.5); // ضبط الحجم
                scene.add(model);
            });

            animate();
        }

        // تشغيل الرسم المتحرك
        function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
        }

        // إعداد Mediapipe FaceMesh
        async function startFaceTracking() {
            const video = document.getElementById("video");
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;

            const faceMesh = new FaceMesh({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
            });

            faceMesh.setOptions({
                maxNumFaces: 1,
                refineLandmarks: true,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });

            faceMesh.onResults(onFaceResults);

            const camera = new Camera(video, {
                onFrame: async () => {
                    await faceMesh.send({ image: video });
                },
                width: 640,
                height: 480
            });

            camera.start();
        }

        // عند العثور على الوجه
        function onFaceResults(results) {
            if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {
                document.getElementById("status").innerText = "Status: Waiting for face";
                startTime = null;
                return;
            }

            if (!startTime) {
                startTime = performance.now();
            }

            const elapsedTime = ((performance.now() - startTime) / 1000).toFixed(2);
            document.getElementById("status").innerText = `Status: Face Detected! Time: ${elapsedTime}s`;

            const faceLandmarks = results.multiFaceLandmarks[0];

            // نقاط العين والأنف
            const leftEye = faceLandmarks[33];
            const rightEye = faceLandmarks[263];
            const nose = faceLandmarks[1];

            // حساب موضع النظارات
            const x = ((leftEye.x + rightEye.x) / 2 - 0.5) * 2;
            const y = -((leftEye.y + rightEye.y) / 2 - 0.5) * 2;
            const z = -((leftEye.z + rightEye.z) / 2) - 2;

            // تحريك النظارات
            if (model) {
                model.position.set(x, y, z);
                model.rotation.set(0, 0, 0); // تجنب الدوران العشوائي
            }
        }

        // بدء التطبيق
        initScene();
        startFaceTracking();
    </script>
</body>
</html>
